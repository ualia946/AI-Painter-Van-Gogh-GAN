# üé® Van-Gogh-GAN: Generador de Arte con Redes Antag√≥nicas

![Imagen del resultado final v2](results/v2/generated_images/image_at_epoch_1024.png)

Este proyecto es una implementaci√≥n de una Red Generativa Antag√≥nica (GAN), espec√≠ficamente una DCGAN (Deep Convolutional GAN), entrenada para generar im√°genes al estilo del pintor Vincent van Gogh. El objetivo principal no era solo construir el modelo, sino tambi√©n entender, diagnosticar y mejorar el proceso de entrenamiento a trav√©s de la experimentaci√≥n iterativa.

## üöÄ Resultados

Tras un proceso de optimizaci√≥n y entrenamiento, el modelo es capaz de generar im√°genes abstractas que capturan la esencia del estilo de Van Gogh, como sus caracter√≠sticas pinceladas y su paleta de colores.

**Mejora a lo largo del tiempo (v2):**
![Gif im√°genes v2](results/v2/van_gogh_evolution.gif)

| √âpoca 1 | √âpoca 500 | √âpoca 1024 |
| :---: | :---: | :---: |
| ![√âpoca 1](results/v2/generated_images/image_at_epoch_0001.png) | ![√âpoca 500](results/v2/generated_images/image_at_epoch_0499.png) | ![√âpoca 1024](results/v2/generated_images/image_at_epoch_1024.png) |

---

## üî¨ An√°lisis del Entrenamiento

Una parte fundamental del proyecto fue analizar y mejorar el rendimiento del modelo. Se realizaron dos experimentos principales.

### Experimento v1: Modelo Base

El primer modelo sufr√≠a de un problema com√∫n en el entrenamiento de GANs: el **colapso del gradiente debido a un discriminador demasiado fuerte (Discriminator Overpowering)**.

| P√©rdidas (v1) | Precisi√≥n (v1) |
| :---: | :---: |
| ![Gr√°fico de P√©rdidas v1](results/v1/grafica_perdidas_v1.png) | ![Gr√°fico de Precisi√≥n v1](results/v1/grafica_precision_v1.png) |

**Observaciones:**
* El Discriminador aprendi√≥ a diferenciar im√°genes reales de falsas mucho m√°s r√°pido que el Generador a crearlas. Esto se debe a que su tarea, similar a la clasificaci√≥n, es intr√≠nsecamente m√°s sencilla que la tarea creativa del Generador.
* Esto caus√≥ que el Discriminador se volviera un "experto arrogante": su precisi√≥n se dispar√≥ r√°pidamente al 90-100%, y su p√©rdida se mantuvo cercana a cero.
* El problema principal surgi√≥ del feedback (gradientes) que recib√≠a el Generador. Cuando el Discriminador estaba tan seguro de que una imagen era falsa (predicci√≥n cercana a 0.0), la se√±al de aprendizaje para el Generador era pr√°cticamente nula. Era como si el cr√≠tico le dijera al artista "todo est√° mal", sin ofrecerle ninguna pista sobre c√≥mo mejorar.
* Como resultado, la p√©rdida del Generador se mantuvo muy alta y vol√°til, demostrando un estancamiento en su aprendizaje.

### Experimento v2: Entrenamiento Mejorado

Para solucionar los problemas de la v1 y equilibrar la competici√≥n, se implementaron dos estrategias clave:

1.  **Ajuste de Tasas de Aprendizaje:** Se aument√≥ la tasa de aprendizaje del Generador (2.5e-4) y se redujo la del Discriminador (1e-4) para darle una ventaja y compensar la mayor dificultad de su tarea.
2.  **Suavizado de Etiquetas (Label Smoothing):** Se cambi√≥ el objetivo para las im√°genes reales de `1.0` a `0.9` en la funci√≥n de p√©rdida del Discriminador.

| P√©rdidas (v2) | Precisi√≥n (v2) |
| :---: | :---: |
| ![Gr√°fico de P√©rdidas v2](results/v2/grafica_perdidas_v2.png) | ![Gr√°fico de Precisi√≥n v2](results/v2/grafica_precision_v2.png) |

**Observaciones:**
* **√âxito de las Estrategias:** Las mejoras tuvieron un impacto dr√°stico y positivo. El suavizado de etiquetas regulariz√≥ al Discriminador, impidi√©ndole volverse "arrogante". Al no poder aspirar a una certeza del 100% (objetivo 1.0), su funci√≥n de decisi√≥n interna se suaviz√≥, pasando de ser un "acantilado" a una "colina".
* **Mejora del Feedback (Gradientes):** El efecto secundario de esta "colina" es que, incluso para las im√°genes falsas (cuyo objetivo segu√≠a siendo 0.0), las predicciones del Discriminador se volvieron menos extremas (ej. `0.15` en lugar de `0.0001`). Esto gener√≥ un gradiente mucho m√°s rico: en lugar de un "todo est√° mal", el Generador recibi√≥ una se√±al matizada que le indicaba qu√© aspectos (como la paleta de colores) iban por buen camino y cu√°les (como las formas) necesitaban mejorar.
* **Resultados en las Gr√°ficas:**
    * La **p√©rdida del Generador (v2)** es ahora mucho m√°s baja y estable, incluso cruz√°ndose y siendo mejor que la del Discriminador en algunas √©pocas. Esto demuestra que est√° recibiendo un feedback √∫til y es un competidor real.
    * La **precisi√≥n del Discriminador (v2)** se ha estabilizado en una "tensi√≥n competitiva saludable" en torno al 70-80%. Esto es ideal: el Discriminador sigue siendo un cr√≠tico competente (acierta la mayor√≠a de las veces), pero el Generador es ahora lo suficientemente bueno como para enga√±arle 2 o 3 veces de cada 10, demostrando que la batalla est√° re√±ida y ambos modelos se fuerzan a mejorar continuamente.

---

## üõ†Ô∏è C√≥mo Usar

### Prerrequisitos
* Python 3.8+
* TensorFlow
* Pandas
* Matplotlib
* (Las versiones exactas est√°n en `requirements.txt`)

### Instalaci√≥n
1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/ia946/Van-Gogh-GAN.git]
    ```
2.  Navega a la carpeta del proyecto:
    ```bash
    cd Van-Gogh-GAN
    ```
3.  Instala las dependencias:
    ```bash
    pip install -r requirements.txt
    ```

### Ejecuci√≥n
Abre y ejecuta el notebook `main.ipynb` en un entorno con Jupyter Notebook o Jupyter Lab.

---

## üíª Tecnolog√≠as Utilizadas
* **Python**
* **TensorFlow / Keras** para la construcci√≥n y entrenamiento del modelo.
* **Pandas** para el manejo de los logs de entrenamiento.
* **Matplotlib** para la visualizaci√≥n de datos e im√°genes.
* **NumPy** para operaciones num√©ricas.

## üîÆ Futuras Mejoras
El siguiente paso natural para este proyecto es evolucionar de un generador a partir de ruido a un modelo de **traducci√≥n de imagen a imagen**. La idea ser√≠a implementar una **CycleGAN** para "traducir" una fotograf√≠a real (ej. un retrato) al estilo art√≠stico de Van Gogh.

## üë§ Autor
* **Ivelin Apostolov**
* **LinkedIn:** `[]`
* **GitHub:** `[https://github.com/ualia946]`

---
