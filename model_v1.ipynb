{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd3490-80c2-48ae-82fc-135514b3549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# --- PARÁMETROS QUE PUEDES AJUSTAR ---\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "DATASET_PATH = \"C:/Users/ivcho/Desktop/Universidad/Proyecto_GAN/dataset/VincentVanGogh\"\n",
    "\n",
    "print(\"Empezando a cargar y preprocesar las imágenes de todas las subcarpetas\")\n",
    "\n",
    "processed_images = []\n",
    "\n",
    "#Para cada carpeta, nos da su ruta (dirpath) y la lista de archivos (filenames).\n",
    "for dirpath, dirnames, filenames in os.walk(DATASET_PATH):\n",
    "    for filename in filenames:\n",
    "        #Construir ruta completa al archivo\n",
    "        path = os.path.join(dirpath, filename)\n",
    "\n",
    "        #Leer imagen con OpenCV\n",
    "        image = cv2.imread(path)\n",
    "\n",
    "        # La convertimos de BGR (formato de OpenCV) a RGB (formato estándar)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #Redimensionamos el tamaño de la imagen\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        processed_images.append(image)\n",
    "\n",
    "#Convertir lista de imágenes procesadas en un array de NumPy\n",
    "X_train = np.array(processed_images)\n",
    "\n",
    "print(\"Valores no normalizados de la imagen [0, 255]\")\n",
    "una_imagen = X_train[1]\n",
    "print(f\"La forma de una sola imagen es: {una_imagen.shape}\")\n",
    "print(\"Estos son los valores de los 3 canales de color (R, G, B) para el píxel en la esquina superior izquierda (coordenada 0,0):\")\n",
    "pixel_esquina = una_imagen[0][0]\n",
    "print(f\"{pixel_esquina}\\n\")\n",
    "\n",
    "\n",
    "#Los modelos GAN funcionan mejor con valores entre 1 y -1, por tanto se proceden a normalizar los valores.\n",
    "print(\"Valores normalizados de la [-1, 1]\")\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "una_imagen = X_train[1]\n",
    "\n",
    "print(f\"La forma de una sola imagen es: {una_imagen.shape}\")\n",
    "\n",
    "print(\"Estos son los valores de los 3 canales de color (R, G, B) para el píxel en la esquina superior izquierda (coordenada 0,0):\")\n",
    "pixel_esquina = una_imagen[0][0]\n",
    "print(f\"{pixel_esquina}\\n\")\n",
    "\n",
    "print(f\"Hecho, se han cargado {len(X_train)} imágenes.\")\n",
    "print(f\"La forma de nuestro set es {X_train.shape}\")\n",
    "\n",
    "# El problema es que matplotlib es como un humano, no entiende el \"idioma\" de la IA.\n",
    "# Para mostrar una imagen correctamente, espera que los valores de los píxeles estén en uno de estos dos rangos:\n",
    "plt.imshow((X_train[1] + 1) / 2) # Se deshace la normalización.\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "#Convertir dataset en un formato eficiente para TensorFlow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(len(X_train)).batch(BATCH_SIZE)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0c03d-729d-44fb-ae9e-7596bb7697bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Definimos el tamaño del vector de ruido. Será la entrada del generador.\n",
    "# Piensa en esto como la \"complejidad\" de la semilla de inspiración. 100 es un valor estándar.\n",
    "NOISE_DIM = 100\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential(name=\"Generador\")\n",
    "     # --- Capa de Entrada: Proyectar el ruido inicial ---\n",
    "    # Tomamos el vector de ruido de 100 dimensiones y lo proyectamos a un espacio más grande.\n",
    "    # 8*8*256 es el tamaño de la primera \"tela\" sobre la que empezará a pintar.\n",
    "    model.add(layers.Dense(8 * 8 * 256, input_dim=NOISE_DIM))\n",
    "    # Usamos LeakyReLU, una activación que funciona muy bien en GANs.\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # --- Darle forma de imagen pequeña ---\n",
    "    # Convertimos el vector en un cubo de (8, 8, 256)\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "\n",
    "    # --- Proceso de Upsampling (Hacer la imagen más grande) ---\n",
    "    # Vamos a ir doblando el tamaño de la imagen y reduciendo el número de filtros.\n",
    "    # Capa 1: de 8x8 a 16x16\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Capa 2: de 16x16 a 32x32\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Capa 3: de 32x32 a 64x64\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Capa 4: de 64x64 a 128x128\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # --- Capa de Salida: La pintura final ---\n",
    "    # La última capa debe tener 3 canales (R, G, B)\n",
    "    # Usamos la activación 'tanh' porque su salida está en el rango [-1, 1],\n",
    "    # ¡exactamente el mismo rango en el que normalizamos nuestras imágenes!\n",
    "    model.add(layers.Conv2D(3, (5, 5), padding='same', activation='tanh'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Construimos el generador\n",
    "generator = build_generator()\n",
    "print(\"--- ARQUITECTURA DEL GENERADOR ---\")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad98eff-67a1-45b5-8f89-348af1583ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = keras.Sequential(name=\"Discriminador\")\n",
    "\n",
    "    #Capa de entrada 128x128x3\n",
    "    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding=\"same\", input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    #Capas ocultas\n",
    "    #64x64x3\n",
    "    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    #32x32x3\n",
    "    model.add(layers.Conv2D(256, (5,5), strides=(2,2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    #16x16x3\n",
    "    #Capa de Salida\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "print(\"--- ARQUITECTURA DEL GENERADOR ---\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58c55c-0082-4eb5-a75f-b2a7d2ca655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# La función de pérdida mide qué tan equivocados están los modelos.\n",
    "# Usamos BinaryCrossentropy porque es un problema de clasificación binaria (0 o 1 / Falso o Real).\n",
    "# from_logits=True es una recomendación técnica para que los cálculos sean más estables.\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "     # El crítico quiere que las imágenes REALES se clasifiquen como 1.\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    \n",
    "    # El crítico quiere que las imágenes FALSAS se clasifiquen como 0\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    # El generador quiere ENGAÑAR al crítico, es decir,\n",
    "    # quiere que sus imágenes FALSAS se clasifiquen como 1.\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer =  tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8cdb9-3579-47e7-a526-cec8d746d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    #1. Generamos ruido para dárselo de comer al generador\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "    \n",
    "    # 2. Usamos GradientTape para \"grabar\" las operaciones y poder calcular los gradientes.\n",
    "    # Necesitamos dos \"grabadoras\", una para cada modelo.\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # 3. El generador crea imágenes falsas a partir del ruido.\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        # 4. El discriminador juzga tanto las imágenes reales como las falsas.\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        # 5. Calculamos las pérdidas para cada uno usando las funciones que definimos antes.\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        # Para las imágenes reales, el objetivo es 1.\n",
    "        # Redondeamos las predicciones y vemos cuántas son iguales a 1.\n",
    "        real_acc = tf.reduce_mean(tf.cast(tf.equal(tf.round(real_output), 1.0), tf.float32))\n",
    "        \n",
    "        # Para las imágenes falsas, el objetivo es 0.\n",
    "        # Redondeamos las predicciones y vemos cuántas son iguales a 0.\n",
    "        fake_acc = tf.reduce_mean(tf.cast(tf.equal(tf.round(fake_output), 0.0), tf.float32))\n",
    "        \n",
    "        # La precisión total es la media de las dos.\n",
    "        total_acc = (real_acc + fake_acc) / 2.0\n",
    "\n",
    "    # 6. Calculamos los gradientes (cómo debe cambiar cada peso para mejorar).\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # 7. Aplicamos esos cambios a los modelos usando los optimizadores.\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380342df-ba72-4238-b726-7bb0044a0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "EPOCHS = 500 # Puedes empezar con 50-100 para probar, 200-500 para mejores resultados.\n",
    "# Usaremos siempre el mismo lote de ruido para generar las imágenes de muestra.\n",
    "# Así podremos ver la evolución del arte del generador desde la misma \"idea\" inicial.\n",
    "seed = tf.random.normal([16, NOISE_DIM])\n",
    "\n",
    "# Asegúrate de crear esta carpeta en el mismo lugar donde tienes tu notebook\n",
    "os.makedirs('gan_images', exist_ok=True)\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # `training` se pone a False para que el modelo se comporte en modo inferencia.\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        # Desnormalizamos la imagen para poder visualizarla correctamente\n",
    "        plt.imshow((predictions[i, :, :, :] + 1) / 2.0)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Guardamos la figura.\n",
    "    plt.savefig('results/v1/gan_images_v1/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    # Creamos el archivo para los logs de entrenamiento\n",
    "    log_file = 'logs/training_log_v1.csv'\n",
    "    with open(log_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Escribimos los títulos de nuestras columnas\n",
    "        writer.writerow(['Epoch', 'Generator_Loss', 'Discriminator_Loss', 'Discriminator_Accuracy'])\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Variables para guardar la media de las métricas de la época\n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_acc = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Por cada lote de imágenes en nuestro dataset...\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss, acc = train_step(image_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            total_acc += acc\n",
    "            num_batches += 1\n",
    "\n",
    "        # Calculamos la media de la época\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        avg_acc = total_acc / num_batches\n",
    "        \n",
    "        # Imprimimos los resultados de la época de forma clara\n",
    "        print(f'Época {epoch + 1} | Pérdida Gen: {avg_gen_loss:.4f} | Pérdida Disc: {avg_disc_loss:.4f} | Precisión Disc: {avg_acc:.2%}')\n",
    "\n",
    "        # Guardamos los resultados de esta época en el archivo CSV.\n",
    "        with open(log_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # Los valores de loss/acc son tensores de TensorFlow, los convertimos a números normales de Python con .numpy()\n",
    "            data_row = [epoch + 1, avg_gen_loss.numpy(), avg_disc_loss.numpy(), avg_acc.numpy()]\n",
    "            writer.writerow(data_row)\n",
    "        \n",
    "        # Al final de cada época, generamos y guardamos una muestra de imágenes.\n",
    "        print(f'Generando imágenes de muestra para la época {epoch + 1}')\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        print (f'Tiempo para la época {epoch + 1} es {time.time()-start} seg\\n')\n",
    "\n",
    "    # Generamos una última muestra al final del todo.\n",
    "    generate_and_save_images(generator, epochs, seed)\n",
    "\n",
    "# --- ¡EMPIEZA LA BATALLA! ---\n",
    "print(\"--- Inciando entrenamiento ---\")\n",
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
